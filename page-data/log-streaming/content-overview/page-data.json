{"componentChunkName":"component---src-pages-log-streaming-content-overview-index-mdx","path":"/log-streaming/content-overview/","result":{"pageContext":{"frontmatter":{"title":"Log Streaming","description":"How does Log Streaming work & how to leverage it","keywords":"ibm cloud"},"relativePagePath":"/log-streaming/content-overview/index.mdx","titleType":"page","MdxNode":{"id":"4d70f673-a8aa-5fa5-b97c-39a54e680aec","children":[],"parent":"1ac87d7f-0246-57b2-9b83-0b926ae8a545","internal":{"content":"---\ntitle: Log Streaming\ndescription: How does Log Streaming work & how to leverage it\nkeywords: 'ibm cloud'\n---\n\n<PageDescription>\n\nWhat is LogDNA Streaming? \n\n</PageDescription>\n\n\nStreaming enables LogDNA to produce content to a message bus queue and Topic. LogDNA streaming helps you to connect third party consumers of topics to ingest into dashboards for visualization of event log data. \n\nThird party horizonal technologies such as Splunk, used in organizations for application management, security and compliance are able to leverage IBM Cloud Log Analysis with LogDNA Streaming.\n\nThe content in this pattern, we'll walk through setting up a sample event stream by utilizing IBM Cloud Event Streams and LogDNA Streaming, to produce events to a topic for a simple consumer application to ingest. \n\nIBM Cloud Event Streams is a high-through put message bus built with Kafka, see [What is Event Streams](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-about) and [Choosing Your Plan](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose)\n\n\n<AnchorLinks small>\n  <AnchorLink>Create IBM Event Streams Instance</AnchorLink>\n  <AnchorLink>Setup Event Streams Demo</AnchorLink>\n  <AnchorLink>Configure LogDNA Streaming</AnchorLink>\n  <AnchorLink>Start LogDNA Streaming to Consumer</AnchorLink>\n</AnchorLinks>\n\n## Create IBM Event Streams Instance\n\nYou'll need to use a previous LogDNA instance or create a new one, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)\n\nFor the demo, an IBM Cloud Event Streams instance is required. Log into IBM Cloud > services and create your Event Streams instance, see [Provision Event Streams Instance](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-connecting#provision_instance)\n\nOnce your IBM Event Stream instance is setup, create a **Service Credential** account and then expand it to show the username, password (apikey) and kafka_brokers_sasl, similar to the screen shown below.\n\n![Service Credential](./images/servicecredential1.png)\n\n** Make a copy of the Service Credential username, password and Kafka_brokers_sasl URL**. \n\n## Setup Event Streams Demo\n\nYou'll need to setup a sample **Topic**, **Producer** and **Consumer**, see [Getting Started Tutorial](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-getting_started).\n\nFor this demo, choose the **kafka-java-console-sample** from the Git Hub repo, [event-streams-samples](https://github.com/ibm-messaging/event-streams-samples).\n\nMake sure to create the sample topic \"**kafka-java-console-sample-topic**\" in your IBM Cloud Event Streams instance, similar to the screen shown below.\n\n![Topic](./images/topic.png)\n\n\nOnce your **Producer** is up and running with the **kafka-java-console-sample-topic**, you should see a screen similar to the one shown below.\n\n![Producer](./images/producer.png)\n\nAfter you've completed the **Getting started Tutorial**, you should now have a **Consumer** running as well, similar to the screen shown below. \n\n![Consumer](./images/consumer.png)\n\n\n## Configure LogDNA Streaming\n\n**Note:** You'll need an instance of LogDNA, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)\n\nLets get started by following the steps below:\n\n1. Login to IBM Cloud, then go to > Observability > logging, and choose your instance of LogDNA. \n2. Select **View LogDNA** \n3. Click on the **Settings** gear icon and choose Streaming.\n\n<InlineNotification>\n\n**Note:** You may need to contact IBM Cloud support to have your LogDNA instance whitelisted, for Streaming to show up in the **Settings** menu selection.\n\n</InlineNotification>\n\nIf your LogDNA Streaming has been whitelisted, you should see a screen similar to the one shown below. \n\n![LogDNA Streaming](./images/eventstreams2.png)\n\n** To configure LogDNA Streaming, follow the instructions below:**\n\n1. Obtain the IBM Cloud Event Streams Service Credential, **username**, **password** and **Kafka_brokers_sasl** URL.\n2. Configure the Event Streams **Service Credential** information in the **LogDNA Streaming** fields.\n3. Click Save.\n4. Next, you'll need to stop the **Producer** from producing events. \n5. Stop the **Producer** by typing in the command **Cntrl**+**C**.\n6. Now bring up the **Consumer** terminal window, notice the constant, **INFO No messages consumed** text, similar to the screen shown below.\n\n![Consumer](./images/producer_stopped.png)\n\n## Start LogDNA Streaming to Consumer\n\nLet's go a head and start LogDNA Streaming, you may see a notice from LogDNA Streaming asking if you've received the sample messages similar to the screen shown below, click yes.\n\n![Samples](./images/sample_logs.png)\n\nAdd in an email recipient and then click start streaming, similar to the screen shown below. \n\n![Streaming Configuration](./images/streaming_configured.png)\n\nLogDNA should now have been successfully configured. If you have a **Kubernetes cluster**,**VSI** or any other services configured with LogDNA enabled, you should see activity in the **Consumer** terminal, similar to the screen shown below. \n\n![LogDNA Streaming Started](./images/logdna_streaming_start.png)\n\nLogDNA **Streaming** is active, similar to the screen shown below. \n\n![Consumer Recevied LogDNA Streams](./images/consumer_logdna_activity.png)\n\n<InlineNotification>\n\n**The Consumer is now consuming an event log topic, that LogDNA Streaming is sending to the IBM Cloud Event Streams message bus**. \n\n</InlineNotification>\n\n\n\n\n","type":"Mdx","contentDigest":"6bb55e41bf8efe28fd2b8893c8d0ad69","counter":653,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Log Streaming","description":"How does Log Streaming work & how to leverage it","keywords":"ibm cloud"},"exports":{},"rawBody":"---\ntitle: Log Streaming\ndescription: How does Log Streaming work & how to leverage it\nkeywords: 'ibm cloud'\n---\n\n<PageDescription>\n\nWhat is LogDNA Streaming? \n\n</PageDescription>\n\n\nStreaming enables LogDNA to produce content to a message bus queue and Topic. LogDNA streaming helps you to connect third party consumers of topics to ingest into dashboards for visualization of event log data. \n\nThird party horizonal technologies such as Splunk, used in organizations for application management, security and compliance are able to leverage IBM Cloud Log Analysis with LogDNA Streaming.\n\nThe content in this pattern, we'll walk through setting up a sample event stream by utilizing IBM Cloud Event Streams and LogDNA Streaming, to produce events to a topic for a simple consumer application to ingest. \n\nIBM Cloud Event Streams is a high-through put message bus built with Kafka, see [What is Event Streams](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-about) and [Choosing Your Plan](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose)\n\n\n<AnchorLinks small>\n  <AnchorLink>Create IBM Event Streams Instance</AnchorLink>\n  <AnchorLink>Setup Event Streams Demo</AnchorLink>\n  <AnchorLink>Configure LogDNA Streaming</AnchorLink>\n  <AnchorLink>Start LogDNA Streaming to Consumer</AnchorLink>\n</AnchorLinks>\n\n## Create IBM Event Streams Instance\n\nYou'll need to use a previous LogDNA instance or create a new one, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)\n\nFor the demo, an IBM Cloud Event Streams instance is required. Log into IBM Cloud > services and create your Event Streams instance, see [Provision Event Streams Instance](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-connecting#provision_instance)\n\nOnce your IBM Event Stream instance is setup, create a **Service Credential** account and then expand it to show the username, password (apikey) and kafka_brokers_sasl, similar to the screen shown below.\n\n![Service Credential](./images/servicecredential1.png)\n\n** Make a copy of the Service Credential username, password and Kafka_brokers_sasl URL**. \n\n## Setup Event Streams Demo\n\nYou'll need to setup a sample **Topic**, **Producer** and **Consumer**, see [Getting Started Tutorial](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-getting_started).\n\nFor this demo, choose the **kafka-java-console-sample** from the Git Hub repo, [event-streams-samples](https://github.com/ibm-messaging/event-streams-samples).\n\nMake sure to create the sample topic \"**kafka-java-console-sample-topic**\" in your IBM Cloud Event Streams instance, similar to the screen shown below.\n\n![Topic](./images/topic.png)\n\n\nOnce your **Producer** is up and running with the **kafka-java-console-sample-topic**, you should see a screen similar to the one shown below.\n\n![Producer](./images/producer.png)\n\nAfter you've completed the **Getting started Tutorial**, you should now have a **Consumer** running as well, similar to the screen shown below. \n\n![Consumer](./images/consumer.png)\n\n\n## Configure LogDNA Streaming\n\n**Note:** You'll need an instance of LogDNA, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)\n\nLets get started by following the steps below:\n\n1. Login to IBM Cloud, then go to > Observability > logging, and choose your instance of LogDNA. \n2. Select **View LogDNA** \n3. Click on the **Settings** gear icon and choose Streaming.\n\n<InlineNotification>\n\n**Note:** You may need to contact IBM Cloud support to have your LogDNA instance whitelisted, for Streaming to show up in the **Settings** menu selection.\n\n</InlineNotification>\n\nIf your LogDNA Streaming has been whitelisted, you should see a screen similar to the one shown below. \n\n![LogDNA Streaming](./images/eventstreams2.png)\n\n** To configure LogDNA Streaming, follow the instructions below:**\n\n1. Obtain the IBM Cloud Event Streams Service Credential, **username**, **password** and **Kafka_brokers_sasl** URL.\n2. Configure the Event Streams **Service Credential** information in the **LogDNA Streaming** fields.\n3. Click Save.\n4. Next, you'll need to stop the **Producer** from producing events. \n5. Stop the **Producer** by typing in the command **Cntrl**+**C**.\n6. Now bring up the **Consumer** terminal window, notice the constant, **INFO No messages consumed** text, similar to the screen shown below.\n\n![Consumer](./images/producer_stopped.png)\n\n## Start LogDNA Streaming to Consumer\n\nLet's go a head and start LogDNA Streaming, you may see a notice from LogDNA Streaming asking if you've received the sample messages similar to the screen shown below, click yes.\n\n![Samples](./images/sample_logs.png)\n\nAdd in an email recipient and then click start streaming, similar to the screen shown below. \n\n![Streaming Configuration](./images/streaming_configured.png)\n\nLogDNA should now have been successfully configured. If you have a **Kubernetes cluster**,**VSI** or any other services configured with LogDNA enabled, you should see activity in the **Consumer** terminal, similar to the screen shown below. \n\n![LogDNA Streaming Started](./images/logdna_streaming_start.png)\n\nLogDNA **Streaming** is active, similar to the screen shown below. \n\n![Consumer Recevied LogDNA Streams](./images/consumer_logdna_activity.png)\n\n<InlineNotification>\n\n**The Consumer is now consuming an event log topic, that LogDNA Streaming is sending to the IBM Cloud Event Streams message bus**. \n\n</InlineNotification>\n\n\n\n\n","fileAbsolutePath":"/Users/johandry/Workspace/ibm/att-cloudnative/ibmcloud-pattern-guide/src/pages/log-streaming/content-overview/index.mdx"}}}}