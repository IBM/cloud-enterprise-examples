---
title: Log Streaming
description: How does Log Streaming work & how to leverage it
keywords: 'ibm cloud'
---

<PageDescription>

What is LogDNA Streaming? 

</PageDescription>


Streaming enables LogDNA to produce content to a message bus queue and Topic. LogDNA streaming helps you to connect third party consumers of topics to ingest into dashboards for visualization of event log data. 

Third party horizonal technologies such as Splunk, used in organizations for application management, security and compliance are able to leverage IBM Cloud Log Analysis with LogDNA Streaming.

The content in this pattern, we'll walk through setting up a sample event stream by utilizing IBM Cloud Event Streams and LogDNA Streaming, to produce events to a topic for a simple consumer application to ingest. 

IBM Cloud Event Streams is a high-through put message bus built with Kafka, see [What is Event Streams](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-about) and [Choosing Your Plan](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose)


<AnchorLinks small>
  <AnchorLink>Create IBM Event Streams Instance</AnchorLink>
  <AnchorLink>Setup Event Streams Demo</AnchorLink>
  <AnchorLink>Configure LogDNA Streaming</AnchorLink>
  <AnchorLink>Start LogDNA Streaming to Consumer</AnchorLink>
</AnchorLinks>
<InlineNotification>

** Please Note:** The functionality of connecting LogDNA to Event Streams is currently available as an `Early Access` only.  You will need approval from IBM to have it enabled for a specific instance of LogDNA.

</InlineNotification>


## Create IBM Event Streams Instance

You'll need to use a previous LogDNA instance or create a new one, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)

For the demo, an IBM Cloud Event Streams instance is required. Log into IBM Cloud > services and create your Event Streams instance, see [Provision Event Streams Instance](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-connecting#provision_instance)

Once your IBM Event Stream instance is setup, create a **Service Credential** account and then expand it to show the username, password (apikey) and kafka_brokers_sasl, similar to the screen shown below.

![Service Credential](./images/servicecredential1.png)

** Make a copy of the Service Credential username, password and Kafka_brokers_sasl URL**. 

## Setup Event Streams Demo

You'll need to setup a sample **Topic**, **Producer** and **Consumer**, see [Getting Started Tutorial](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-getting_started).

For this demo, choose the **kafka-java-console-sample** from the Git Hub repo, [event-streams-samples](https://github.com/ibm-messaging/event-streams-samples).

Make sure to create the sample topic "**kafka-java-console-sample-topic**" in your IBM Cloud Event Streams instance, similar to the screen shown below.

![Topic](./images/topic.png)


Once your **Producer** is up and running with the **kafka-java-console-sample-topic**, you should see a screen similar to the one shown below.

![Producer](./images/producer.png)

After you've completed the **Getting started Tutorial**, you should now have a **Consumer** running as well, similar to the screen shown below. 

![Consumer](./images/consumer.png)


## Configure LogDNA Streaming

**Note:** You'll need an instance of LogDNA, see [Provisioning an Instance](https://cloud.ibm.com/docs/Activity-Tracker-with-LogDNA?topic=Activity-Tracker-with-LogDNA-provision)

Lets get started by following the steps below:

1. Login to IBM Cloud, then go to > Observability > logging, and choose your instance of LogDNA. 
2. Select **View LogDNA** 
3. Click on the **Settings** gear icon and choose Streaming.

<InlineNotification>

**Note:** You may need to contact IBM Cloud support to have your LogDNA instance whitelisted, for Streaming to show up in the **Settings** menu selection.

</InlineNotification>

If your LogDNA Streaming has been whitelisted, you should see a screen similar to the one shown below. 

![LogDNA Streaming](./images/eventstreams2.png)

** To configure LogDNA Streaming, follow the instructions below:**

1. Obtain the IBM Cloud Event Streams Service Credential, **username**, **password** and **Kafka_brokers_sasl** URL.
2. Configure the Event Streams **Service Credential** information in the **LogDNA Streaming** fields.
3. Click Save.
4. Next, you'll need to stop the **Producer** from producing events. 
5. Stop the **Producer** by typing in the command **Cntrl**+**C**.
6. Now bring up the **Consumer** terminal window, notice the constant, **INFO No messages consumed** text, similar to the screen shown below.

![Consumer](./images/producer_stopped.png)

## Start LogDNA Streaming to Consumer

Let's go a head and start LogDNA Streaming, you may see a notice from LogDNA Streaming asking if you've received the sample messages similar to the screen shown below, click yes.

![Samples](./images/sample_logs.png)

Add in an email recipient and then click start streaming, similar to the screen shown below. 

![Streaming Configuration](./images/streaming_configured.png)

LogDNA should now have been successfully configured. If you have a **Kubernetes cluster**,**VSI** or any other services configured with LogDNA enabled, you should see activity in the **Consumer** terminal, similar to the screen shown below. 

![LogDNA Streaming Started](./images/logdna_streaming_start.png)

LogDNA **Streaming** is active, similar to the screen shown below. 

![Consumer Recevied LogDNA Streams](./images/consumer_logdna_activity.png)

<InlineNotification>

**The Consumer is now consuming an event log topic, that LogDNA Streaming is sending to the IBM Cloud Event Streams message bus**. 

## djb Test
</InlineNotification>




